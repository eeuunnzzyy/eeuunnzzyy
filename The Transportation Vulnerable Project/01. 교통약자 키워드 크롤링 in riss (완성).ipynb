{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c84416a1",
   "metadata": {},
   "source": [
    "# 자율주행 키워드 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d581bfe",
   "metadata": {},
   "source": [
    "## 환경세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90a39103",
   "metadata": {},
   "outputs": [],
   "source": [
    "#분석 환경 세팅\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import re\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "from openpyxl import Workbook\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests\n",
    "import os\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ba97ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3q/y966c1fj3lndmps8kk3plpy40000gn/T/ipykernel_17963/161936369.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path='/Users/jeon-eunji/Documents/GitHub/TIL/크롤링/chromedriver')\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(executable_path='/Users/jeon-eunji/Documents/GitHub/TIL/크롤링/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301691cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#분석 진행상황 확인 및 경고창 무시하기\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a0b913",
   "metadata": {},
   "source": [
    "# 분석하기 1\n",
    "## url 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b6174",
   "metadata": {},
   "source": [
    "- 오른쪽 콘텐츠 쪽 상위 카테고리에서 연도별, 내림차순으로 선택한 후 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "def1b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://www.riss.kr/search/Search.do?isDetailSearch=N&searchGubun=true&viewYn=OP&queryText=&strQuery=자율주행Query=pyear%3A2022%E2%97%88pyear%3A2021%E2%97%88pyear%3A2020%E2%97%88pyear%3A2019%E2%97%88pyear%3A2018%E2%97%88&exQueryText=%EB%B0%9C%ED%96%89%EC%97%B0%EB%8F%84+%5B2022%5D%40%40pyear%3A2022%E2%97%88%EB%B0%9C%ED%96%89%EC%97%B0%EB%8F%84+%5B2021%5D%40%40pyear%3A2021%E2%97%88%EB%B0%9C%ED%96%89%EC%97%B0%EB%8F%84+%5B2020%5D%40%40pyear%3A2020%E2%97%88%EB%B0%9C%ED%96%89%EC%97%B0%EB%8F%84+%5B2019%5D%40%40pyear%3A2019%E2%97%88%EB%B0%9C%ED%96%89%EC%97%B0%EB%8F%84+%5B2018%5D%40%40pyear%3A2018%E2%97%88&order=%2FDESC&onHanja=false&strSort=DATE&p_year1=&p_year2=&iStartCount=100&orderBy=&mat_type=&mat_subtype=&fulltext_kind=&t_gubun=&learning_type=&ccl_code=&inside_outside=&fric_yn=&image_yn=&gubun=&kdc=&ttsUseYn=&l_sub_code=&fsearchMethod=search&sflag=1&isFDetailSearch=N&pageNumber=1&resultKeyword=%EC%9E%90%EC%9C%A8%EC%A3%BC%ED%96%89&fsearchSort=&fsearchOrder=&limiterList=&limiterListText=&facetList=&facetListText=&fsearchDB=&icate=re_a_kor&colName=re_a_kor&pageScale=100&isTab=Y&regnm=&dorg_storage=&language=&language_code=&clickKeyword=&relationKeyword=&query=%EC%9E%90%EC%9C%A8%EC%A3%BC%ED%96%89\n",
    "#이 URL을 위 아래로 쪼개야 한다. \n",
    "#이러면 페이지 구분없이, 입력된 page\n",
    "\n",
    "#키워드 입력\n",
    "키워드 = '교통약자'\n",
    "\n",
    "#URL 앞 -- 키워드 변경 가능\n",
    "\n",
    "url_front = f\"http://www.riss.kr/search/Search.do?isDetailSearch=N&searchGubun=true&viewYn=OP&queryText=&strQuery={키워드}&exQuery=&exQueryText=&order=%2FDESC&onHanja=false&strSort=DATE&p_year1=&p_year2=&iStartCount=\"\n",
    "#URL 뒤 -- \n",
    "url_back = f\"&orderBy=&mat_type=&mat_subtype=&fulltext_kind=&t_gubun=&learning_type=&ccl_code=&inside_outside=&fric_yn=&image_yn=&gubun=&kdc=&ttsUseYn=&l_sub_code=&fsearchMethod=&sflag=1&isFDetailSearch=N&pageNumber=1&resultKeyword={키워드}&fsearchSort=&fsearchOrder=&limiterList=&limiterListText=&facetList=&facetListText=&fsearchDB=&icate=re_a_kor&colName=re_a_kor&pageScale=10&isTab=Y&regnm=&dorg_storage=&language=&language_code=&clickKeyword=&relationKeyword=&query={키워드}\"\n",
    "\n",
    "#get_URL 함수 정의\n",
    "def get_URL(page):\n",
    "    URL = url_front + page + url_back\n",
    "    return URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "647ca16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#논문 검색시 나온 검색결과가 652건. 10단위로 끊어지는게 좋으니까\n",
    "#그러면 range(0,65)\n",
    "page_URL = []\n",
    "for i in range(0,65):\n",
    "    a = get_URL(str(i*10))\n",
    "    page_URL.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "320f2d7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(page_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b7135fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>저자</th>\n",
       "      <th>발행기관</th>\n",
       "      <th>발행연도</th>\n",
       "      <th>핵심어</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>군집분석을 통한 서울시의 무장애 버스정류장 입지선정</td>\n",
       "      <td>김세형</td>\n",
       "      <td>한국품질경영학회(The Korean Society for Quality Manage...</td>\n",
       "      <td>2022</td>\n",
       "      <td>[무장애 버스정류장, 군집분석, k-means, 입지선정]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On-demand 자율주행 서비스를 위한 세종시 대중교통 음영지역에 대한 분석</td>\n",
       "      <td>이대국(Lee Dae Kug)</td>\n",
       "      <td>한국통신학회</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>스마트 교통신호등 시스템 구현                      = Implem...</td>\n",
       "      <td>이동은</td>\n",
       "      <td>한국지식정보기술학회</td>\n",
       "      <td>2022</td>\n",
       "      <td>[Bluetooth low energy, Beacon, Smart traffic l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>시각적 교통약자를 위한 길안내 데이터 모델 구축에 관한 연구             ...</td>\n",
       "      <td>박성호</td>\n",
       "      <td>한국측량학회</td>\n",
       "      <td>2022</td>\n",
       "      <td>[Visually impaired, Traffic-impaired, Road gui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>한강 자전거도로의 노면 표시에 관한 연구 : 유도선(Color Lane)을 중심으로...</td>\n",
       "      <td>김상식(Kim Sang Sik)</td>\n",
       "      <td>휴먼이미지디자인학회</td>\n",
       "      <td>2022</td>\n",
       "      <td>[자전거도로 교차점 및 분기점, 노면 유도선, 이용자 안전, 사인정보, Bicycl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[교통 관련 보도자료 중계] 보도자료를 통해 본 주요교통뉴스</td>\n",
       "      <td>김동준</td>\n",
       "      <td>한국교통연구원(KOTI)</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>자율주행 기술 기반 농어촌용 셔틀버스 디자인 연구                   ...</td>\n",
       "      <td>김유현</td>\n",
       "      <td>한국기초조형학회(Korean Society of Basic Design &amp; Art)</td>\n",
       "      <td>2020</td>\n",
       "      <td>[Aging of Population, Rural, Public Transporta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>교통약자의 복합상업시설 접근성에 대한 실증적 연구                   ...</td>\n",
       "      <td>조상원</td>\n",
       "      <td>한국주거학회</td>\n",
       "      <td>2020</td>\n",
       "      <td>[교통약자, 접근성, 배리어프리 디자인, 복합상업시설, 실증적 연구, The Mob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>어린이보호구역에서 Gateway가 주행차량속도 감소에 미치는 효과          ...</td>\n",
       "      <td>임성준</td>\n",
       "      <td>대한교통학회</td>\n",
       "      <td>2020</td>\n",
       "      <td>[Gateway(관문형안전표지), 보행자시인성, 어린이보호구역, 규정속도, 교통안전...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>이용자 만족도 조사를 통한 철도역사 내 교통약자 경로안내 시스템 평가        ...</td>\n",
       "      <td>정은비</td>\n",
       "      <td>대한교통학회</td>\n",
       "      <td>2020</td>\n",
       "      <td>[mobility handicapped, questionnaire, route gu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title                 저자  \\\n",
       "0                        군집분석을 통한 서울시의 무장애 버스정류장 입지선정                김세형   \n",
       "1         On-demand 자율주행 서비스를 위한 세종시 대중교통 음영지역에 대한 분석   이대국(Lee Dae Kug)   \n",
       "2   스마트 교통신호등 시스템 구현                      = Implem...                이동은   \n",
       "3   시각적 교통약자를 위한 길안내 데이터 모델 구축에 관한 연구             ...                박성호   \n",
       "4   한강 자전거도로의 노면 표시에 관한 연구 : 유도선(Color Lane)을 중심으로...  김상식(Kim Sang Sik)   \n",
       "..                                                ...                ...   \n",
       "95                  [교통 관련 보도자료 중계] 보도자료를 통해 본 주요교통뉴스                김동준   \n",
       "96  자율주행 기술 기반 농어촌용 셔틀버스 디자인 연구                   ...                김유현   \n",
       "97  교통약자의 복합상업시설 접근성에 대한 실증적 연구                   ...                조상원   \n",
       "98  어린이보호구역에서 Gateway가 주행차량속도 감소에 미치는 효과          ...                임성준   \n",
       "99  이용자 만족도 조사를 통한 철도역사 내 교통약자 경로안내 시스템 평가        ...                정은비   \n",
       "\n",
       "                                                 발행기관  발행연도  \\\n",
       "0   한국품질경영학회(The Korean Society for Quality Manage...  2022   \n",
       "1                                              한국통신학회  2022   \n",
       "2                                          한국지식정보기술학회  2022   \n",
       "3                                              한국측량학회  2022   \n",
       "4                                          휴먼이미지디자인학회  2022   \n",
       "..                                                ...   ...   \n",
       "95                                      한국교통연구원(KOTI)  2020   \n",
       "96     한국기초조형학회(Korean Society of Basic Design & Art)  2020   \n",
       "97                                             한국주거학회  2020   \n",
       "98                                             대한교통학회  2020   \n",
       "99                                             대한교통학회  2020   \n",
       "\n",
       "                                                  핵심어  \n",
       "0                    [무장애 버스정류장, 군집분석, k-means, 입지선정]  \n",
       "1                                                 NaN  \n",
       "2   [Bluetooth low energy, Beacon, Smart traffic l...  \n",
       "3   [Visually impaired, Traffic-impaired, Road gui...  \n",
       "4   [자전거도로 교차점 및 분기점, 노면 유도선, 이용자 안전, 사인정보, Bicycl...  \n",
       "..                                                ...  \n",
       "95                                                NaN  \n",
       "96  [Aging of Population, Rural, Public Transporta...  \n",
       "97  [교통약자, 접근성, 배리어프리 디자인, 복합상업시설, 실증적 연구, The Mob...  \n",
       "98  [Gateway(관문형안전표지), 보행자시인성, 어린이보호구역, 규정속도, 교통안전...  \n",
       "99  [mobility handicapped, questionnaire, route gu...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(executable_path='/Users/jeon-eunji/Documents/GitHub/TIL/크롤링/chromedriver')\n",
    "front = []\n",
    "letsdigin = []\n",
    "bring_url_pre = []\n",
    "n_url = []\n",
    "real_url = []\n",
    "real_t = []\n",
    "realsoup = []\n",
    "real_page_source = []\n",
    "real_soup = []\n",
    "\n",
    "\n",
    "\n",
    "가져올페이지수 = 10\n",
    "for i in range(가져올페이지수):\n",
    "    get_t_v = requests.get(page_URL[i])\n",
    "    soup = BeautifulSoup(get_t_v.content, 'html.parser')\n",
    "    front.append(soup)\n",
    "    dig_in = front[i].select('div.srchResultListW > ul > li')  \n",
    "    for j in range(0,10):\n",
    "        inval = dig_in[j].find('p', {'class' :'title'})\n",
    "        letsdigin.append(inval)\n",
    "for page in range(가져올페이지수*10):\n",
    "    bring_url_pre_val = letsdigin[page].select('a')\n",
    "    bring_url_pre.append(bring_url_pre_val)\n",
    "\n",
    "for n in range(len(bring_url_pre)):\n",
    "    real_url_val = \"http://www.riss.kr\" + bring_url_pre[n][0].get('href')\n",
    "    real_url.append(real_url_val)\n",
    "    driver.get(real_url[n])\n",
    "    time.sleep(2)\n",
    "    real_page_source_val = driver.page_source\n",
    "    real_page_source.append(real_page_source_val)\n",
    "    real_soup_val = BeautifulSoup(real_page_source[n], 'html.parser')\n",
    "    real_soup.append(real_soup_val)\n",
    "    \n",
    "driver = webdriver.Chrome(executable_path='/Users/jeon-eunji/Documents/GitHub/TIL/크롤링/chromedriver')\n",
    "detail_box = []\n",
    "title = []\n",
    "저자 = []\n",
    "발행기관 = []\n",
    "발행연도 = []\n",
    "핵심어 = []\n",
    "주제어 = []\n",
    "reference_data = pd.DataFrame(columns = ['title', '저자', '발행기관', '발행연도', '핵심어'])\n",
    "############ 제목 ############\n",
    "for r in range(len(real_soup)):\n",
    "    detail_title = real_soup[r].find(\"h3\", \"title\")\n",
    "#get_text()메서드는 현재 태그를 포함하여 모든 하위 태그를 제거하고 유니코드 텍스트만 들어있는 문자열을 반환한다.\n",
    "    title_txt_val1 = detail_title.get_text(\"\", strip = True)\n",
    "    title_txt_val2 = title_txt_val1.replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "    title.append(title_txt_val2)\n",
    "    title_df = pd.DataFrame(title)\n",
    "######저자[0], 발행기관[1], 발행연도 [4], 주제어\n",
    "    detail = real_soup[r].select('div.infoDetailL > ul > li')\n",
    "    \n",
    "    저자_val = detail[0].find_all(\"a\")[0].get_text(\"\", strip = True)\n",
    "    저자.append(저자_val)\n",
    "    저자_df = pd.DataFrame(저자)\n",
    "    \n",
    "    발행기관_val = detail[1].find_all(\"a\")[0].get_text(\"\", strip=True)\n",
    "    발행기관.append(발행기관_val)\n",
    "    발행기관_df = pd.DataFrame(발행기관)\n",
    "    \n",
    "    발행연도_val = detail[4].find_all(\"p\")[0].get_text(\"\", strip = True)\n",
    "    발행연도.append(발행연도_val)\n",
    "    발행연도_df = pd.DataFrame(발행연도)\n",
    "\n",
    "###핵심어\n",
    "핵심어 = pd.DataFrame(index=range(0,len(real_soup)), columns = {'s'})\n",
    "핵심어[\"s\"] = np.nan\n",
    "\n",
    "for r in range(len(real_soup)):\n",
    "    detail = real_soup[r].select('div.infoDetailL > ul > li')\n",
    "    주제어 = []\n",
    "    for i in range(len(detail[6].find_all(\"a\"))): \n",
    "        detail_1_val = detail[6].find_all(\"a\")[i].get_text(\"\", strip = True)\n",
    "        주제어.append(detail_1_val)\n",
    "        핵심어.loc[r,'s'] = 주제어\n",
    "핵심어\n",
    "\n",
    "##합치기\n",
    "reference_1 = pd.concat([title_df, 저자_df, 발행기관_df, 발행연도_df], axis=1)\n",
    "reference_1\n",
    "\n",
    "교통약자_data01 = pd.concat([reference_1, 핵심어], axis = 1)\n",
    "교통약자_data01.columns = ['title', '저자', '발행기관', '발행연도', '핵심어']\n",
    "교통약자_data01\n",
    "교통약자_data01.to_csv(\"교통약자01.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78670f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path='/Users/jeon-eunji/Documents/GitHub/TIL/크롤링/chromedriver')\n",
    "front = []\n",
    "letsdigin = []\n",
    "bring_url_pre = []\n",
    "n_url = []\n",
    "real_url = []\n",
    "real_t = []\n",
    "realsoup = []\n",
    "real_page_source = []\n",
    "real_soup = []\n",
    "\n",
    "\n",
    "\n",
    "가져올페이지수 = 10\n",
    "for i in range(10, 20):\n",
    "    get_t_v = requests.get(page_URL[i])\n",
    "    soup = BeautifulSoup(get_t_v.content, 'html.parser')\n",
    "    front.append(soup)\n",
    "for i in range(가져올페이지수):\n",
    "    dig_in = front[i].select('div.srchResultListW > ul > li')  \n",
    "    for j in range(0,10):\n",
    "        inval = dig_in[j].find('p', {'class' :'title'})\n",
    "        letsdigin.append(inval)\n",
    "for page in range(가져올페이지수*10):\n",
    "    bring_url_pre_val = letsdigin[page].select('a')\n",
    "    bring_url_pre.append(bring_url_pre_val)\n",
    "\n",
    "for n in range(len(bring_url_pre)):\n",
    "    real_url_val = \"http://www.riss.kr\" + bring_url_pre[n][0].get('href')\n",
    "    real_url.append(real_url_val)\n",
    "    driver.get(real_url[n])\n",
    "    time.sleep(2)\n",
    "    real_page_source_val = driver.page_source\n",
    "    real_page_source.append(real_page_source_val)\n",
    "    real_soup_val = BeautifulSoup(real_page_source[n], 'html.parser')\n",
    "    real_soup.append(real_soup_val)\n",
    "    \n",
    "driver = webdriver.Chrome(executable_path='/Users/jeon-eunji/Documents/GitHub/TIL/크롤링/chromedriver')\n",
    "detail_box = []\n",
    "title = []\n",
    "저자 = []\n",
    "발행기관 = []\n",
    "발행연도 = []\n",
    "핵심어 = []\n",
    "주제어 = []\n",
    "reference_data = pd.DataFrame(columns = ['title', '저자', '발행기관', '발행연도', '핵심어'])\n",
    "############ 제목 ############\n",
    "for r in range(len(real_soup)):\n",
    "    detail_title = real_soup[r].find(\"h3\", \"title\")\n",
    "#get_text()메서드는 현재 태그를 포함하여 모든 하위 태그를 제거하고 유니코드 텍스트만 들어있는 문자열을 반환한다.\n",
    "    title_txt_val1 = detail_title.get_text(\"\", strip = True)\n",
    "    title_txt_val2 = title_txt_val1.replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "    title.append(title_txt_val2)\n",
    "    title_df = pd.DataFrame(title)\n",
    "######저자[0], 발행기관[1], 발행연도 [4], 주제어\n",
    "    detail = real_soup[r].select('div.infoDetailL > ul > li')\n",
    "    \n",
    "    저자_val = detail[0].find_all(\"a\")[0].get_text(\"\", strip = True)\n",
    "    저자.append(저자_val)\n",
    "    저자_df = pd.DataFrame(저자)\n",
    "    \n",
    "    발행기관_val = detail[1].find_all(\"a\")[0].get_text(\"\", strip=True)\n",
    "    발행기관.append(발행기관_val)\n",
    "    발행기관_df = pd.DataFrame(발행기관)\n",
    "    \n",
    "    발행연도_val = detail[4].find_all(\"p\")[0].get_text(\"\", strip = True)\n",
    "    발행연도.append(발행연도_val)\n",
    "    발행연도_df = pd.DataFrame(발행연도)\n",
    "\n",
    "###핵심어\n",
    "핵심어 = pd.DataFrame(index=range(0,len(real_soup)), columns = {'s'})\n",
    "핵심어[\"s\"] = np.nan\n",
    "\n",
    "for r in range(len(real_soup)):\n",
    "    detail = real_soup[r].select('div.infoDetailL > ul > li')\n",
    "    주제어 = []\n",
    "    for i in range(len(detail[6].find_all(\"a\"))): \n",
    "        detail_1_val = detail[6].find_all(\"a\")[i].get_text(\"\", strip = True)\n",
    "        주제어.append(detail_1_val)\n",
    "        핵심어.loc[r,'s'] = 주제어\n",
    "핵심어\n",
    "\n",
    "##합치기\n",
    "reference_1 = pd.concat([title_df, 저자_df, 발행기관_df, 발행연도_df], axis=1)\n",
    "reference_1\n",
    "\n",
    "교통약자_data02 = pd.concat([reference_1, 핵심어], axis = 1)\n",
    "교통약자_data02.columns = ['title', '저자', '발행기관', '발행연도', '핵심어']\n",
    "교통약자_data02\n",
    "교통약자_data02.to_csv(\"교통약자02.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c99b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path='/Users/jeon-eunji/Documents/GitHub/TIL/크롤링/chromedriver')\n",
    "front = []\n",
    "letsdigin = []\n",
    "bring_url_pre = []\n",
    "n_url = []\n",
    "real_url = []\n",
    "real_t = []\n",
    "realsoup = []\n",
    "real_page_source = []\n",
    "real_soup = []\n",
    "\n",
    "\n",
    "\n",
    "가져올페이지수 = 10\n",
    "for i in range(20, 30):\n",
    "    get_t_v = requests.get(page_URL[i])\n",
    "    soup = BeautifulSoup(get_t_v.content, 'html.parser')\n",
    "    front.append(soup)\n",
    "for i in range(가져올페이지수):\n",
    "    dig_in = front[i].select('div.srchResultListW > ul > li')  \n",
    "    for j in range(0,10):\n",
    "        inval = dig_in[j].find('p', {'class' :'title'})\n",
    "        letsdigin.append(inval)\n",
    "for page in range(가져올페이지수*10):\n",
    "    bring_url_pre_val = letsdigin[page].select('a')\n",
    "    bring_url_pre.append(bring_url_pre_val)\n",
    "\n",
    "for n in range(len(bring_url_pre)):\n",
    "    real_url_val = \"http://www.riss.kr\" + bring_url_pre[n][0].get('href')\n",
    "    real_url.append(real_url_val)\n",
    "    driver.get(real_url[n])\n",
    "    time.sleep(2)\n",
    "    real_page_source_val = driver.page_source\n",
    "    real_page_source.append(real_page_source_val)\n",
    "    real_soup_val = BeautifulSoup(real_page_source[n], 'html.parser')\n",
    "    real_soup.append(real_soup_val)\n",
    "    \n",
    "driver = webdriver.Chrome(executable_path='/Users/jeon-eunji/Documents/GitHub/TIL/크롤링/chromedriver')\n",
    "detail_box = []\n",
    "title = []\n",
    "저자 = []\n",
    "발행기관 = []\n",
    "발행연도 = []\n",
    "핵심어 = []\n",
    "주제어 = []\n",
    "reference_data = pd.DataFrame(columns = ['title', '저자', '발행기관', '발행연도', '핵심어'])\n",
    "############ 제목 ############\n",
    "for r in range(len(real_soup)):\n",
    "    detail_title = real_soup[r].find(\"h3\", \"title\")\n",
    "#get_text()메서드는 현재 태그를 포함하여 모든 하위 태그를 제거하고 유니코드 텍스트만 들어있는 문자열을 반환한다.\n",
    "    title_txt_val1 = detail_title.get_text(\"\", strip = True)\n",
    "    title_txt_val2 = title_txt_val1.replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "    title.append(title_txt_val2)\n",
    "    title_df = pd.DataFrame(title)\n",
    "######저자[0], 발행기관[1], 발행연도 [4], 주제어\n",
    "    detail = real_soup[r].select('div.infoDetailL > ul > li')\n",
    "    \n",
    "    저자_val = detail[0].find_all(\"a\")[0].get_text(\"\", strip = True)\n",
    "    저자.append(저자_val)\n",
    "    저자_df = pd.DataFrame(저자)\n",
    "    \n",
    "    발행기관_val = detail[1].find_all(\"a\")[0].get_text(\"\", strip=True)\n",
    "    발행기관.append(발행기관_val)\n",
    "    발행기관_df = pd.DataFrame(발행기관)\n",
    "    \n",
    "    발행연도_val = detail[4].find_all(\"p\")[0].get_text(\"\", strip = True)\n",
    "    발행연도.append(발행연도_val)\n",
    "    발행연도_df = pd.DataFrame(발행연도)\n",
    "\n",
    "###핵심어\n",
    "핵심어 = pd.DataFrame(index=range(0,len(real_soup)), columns = {'s'})\n",
    "핵심어[\"s\"] = np.nan\n",
    "\n",
    "for r in range(len(real_soup)):\n",
    "    detail = real_soup[r].select('div.infoDetailL > ul > li')\n",
    "    주제어 = []\n",
    "    for i in range(len(detail[6].find_all(\"a\"))): \n",
    "        detail_1_val = detail[6].find_all(\"a\")[i].get_text(\"\", strip = True)\n",
    "        주제어.append(detail_1_val)\n",
    "        핵심어.loc[r,'s'] = 주제어\n",
    "핵심어\n",
    "\n",
    "##합치기\n",
    "reference_1 = pd.concat([title_df, 저자_df, 발행기관_df, 발행연도_df], axis=1)\n",
    "reference_1\n",
    "\n",
    "교통약자_data03 = pd.concat([reference_1, 핵심어], axis = 1)\n",
    "교통약자_data03.columns = ['title', '저자', '발행기관', '발행연도', '핵심어']\n",
    "교통약자_data03\n",
    "교통약자_data03.to_csv(\"교통약자03.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30d2bd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##안되던거\n",
    "\n",
    "driver = webdriver.Chrome(executable_path='/Users/jeon-eunji/Documents/GitHub/TIL/크롤링/chromedriver')\n",
    "front = []\n",
    "letsdigin = []\n",
    "bring_url_pre = []\n",
    "n_url = []\n",
    "real_url = []\n",
    "real_t = []\n",
    "realsoup = []\n",
    "real_page_source = []\n",
    "real_soup = []\n",
    "\n",
    "\n",
    "\n",
    "가져올페이지수 = 5\n",
    "for i in range(30, 35):\n",
    "    get_t_v = requests.get(page_URL[i])\n",
    "    soup = BeautifulSoup(get_t_v.content, 'html.parser')\n",
    "    front.append(soup)\n",
    "for i in range(가져올페이지수):\n",
    "    dig_in = front[i].select('div.srchResultListW > ul > li')  \n",
    "    for j in range(0,10):\n",
    "        inval = dig_in[j].find('p', {'class' :'title'})\n",
    "        letsdigin.append(inval)\n",
    "for page in range(가져올페이지수*10):\n",
    "    bring_url_pre_val = letsdigin[page].select('a')\n",
    "    bring_url_pre.append(bring_url_pre_val)\n",
    "\n",
    "for n in range(len(bring_url_pre)):\n",
    "    real_url_val = \"http://www.riss.kr\" + bring_url_pre[n][0].get('href')\n",
    "    real_url.append(real_url_val)\n",
    "    driver.get(real_url[n])\n",
    "    time.sleep(2)\n",
    "    real_page_source_val = driver.page_source\n",
    "    real_page_source.append(real_page_source_val)\n",
    "    real_soup_val = BeautifulSoup(real_page_source[n], 'html.parser')\n",
    "    real_soup.append(real_soup_val)\n",
    "    \n",
    "driver = webdriver.Chrome(executable_path='/Users/jeon-eunji/Documents/GitHub/TIL/크롤링/chromedriver')\n",
    "detail_box = []\n",
    "title = []\n",
    "저자 = []\n",
    "발행기관 = []\n",
    "발행연도 = []\n",
    "핵심어 = []\n",
    "주제어 = []\n",
    "reference_data = pd.DataFrame(columns = ['title', '저자', '발행기관', '발행연도', '핵심어'])\n",
    "############ 제목 ############\n",
    "for r in range(len(real_soup)):\n",
    "    detail_title = real_soup[r].find(\"h3\", \"title\")\n",
    "#get_text()메서드는 현재 태그를 포함하여 모든 하위 태그를 제거하고 유니코드 텍스트만 들어있는 문자열을 반환한다.\n",
    "    title_txt_val1 = detail_title.get_text(\"\", strip = True)\n",
    "    title_txt_val2 = title_txt_val1.replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "    title.append(title_txt_val2)\n",
    "    title_df = pd.DataFrame(title)\n",
    "######저자[0], 발행기관[1], 발행연도 [4], 주제어\n",
    "    detail = real_soup[r].select('div.infoDetailL > ul > li')\n",
    "    \n",
    "    저자_val = detail[0].find_all(\"a\")[0].get_text(\"\", strip = True)\n",
    "    저자.append(저자_val)\n",
    "    저자_df = pd.DataFrame(저자)\n",
    "    \n",
    "    발행기관_val = detail[1].find_all(\"a\")[0].get_text(\"\", strip=True)\n",
    "    발행기관.append(발행기관_val)\n",
    "    발행기관_df = pd.DataFrame(발행기관)\n",
    "    \n",
    "    발행연도_val = detail[4].find_all(\"p\")[0].get_text(\"\", strip = True)\n",
    "    발행연도.append(발행연도_val)\n",
    "    발행연도_df = pd.DataFrame(발행연도)\n",
    "\n",
    "###핵심어\n",
    "핵심어 = pd.DataFrame(index=range(0,len(real_soup)), columns = {'s'})\n",
    "핵심어[\"s\"] = np.nan\n",
    "\n",
    "for r in range(len(real_soup)):\n",
    "    detail = real_soup[r].select('div.infoDetailL > ul > li')\n",
    "    주제어 = []\n",
    "    for i in range(len(detail[6].find_all(\"a\"))): \n",
    "        detail_1_val = detail[6].find_all(\"a\")[i].get_text(\"\", strip = True)\n",
    "        주제어.append(detail_1_val)\n",
    "        핵심어.loc[r,'s'] = 주제어\n",
    "핵심어\n",
    "\n",
    "##합치기\n",
    "reference_1 = pd.concat([title_df, 저자_df, 발행기관_df, 발행연도_df], axis=1)\n",
    "reference_1\n",
    "\n",
    "교통약자_data04 = pd.concat([reference_1, 핵심어], axis = 1)\n",
    "교통약자_data04.columns = ['title', '저자', '발행기관', '발행연도', '핵심어']\n",
    "교통약자_data04\n",
    "교통약자_data04.to_csv(\"교통약자04.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48d2b3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path='/Users/jeon-eunji/Documents/GitHub/TIL/크롤링/chromedriver')\n",
    "front = []\n",
    "letsdigin = []\n",
    "bring_url_pre = []\n",
    "n_url = []\n",
    "real_url = []\n",
    "real_t = []\n",
    "realsoup = []\n",
    "real_page_source = []\n",
    "real_soup = []\n",
    "\n",
    "\n",
    "\n",
    "가져올페이지수 = 5\n",
    "for i in range(35, 40):\n",
    "    get_t_v = requests.get(page_URL[i])\n",
    "    soup = BeautifulSoup(get_t_v.content, 'html.parser')\n",
    "    front.append(soup)\n",
    "for i in range(가져올페이지수):\n",
    "    dig_in = front[i].select('div.srchResultListW > ul > li')  \n",
    "    for j in range(0,10):\n",
    "        inval = dig_in[j].find('p', {'class' :'title'})\n",
    "        letsdigin.append(inval)\n",
    "for page in range(가져올페이지수*10):\n",
    "    bring_url_pre_val = letsdigin[page].select('a')\n",
    "    bring_url_pre.append(bring_url_pre_val)\n",
    "\n",
    "for n in range(len(bring_url_pre)):\n",
    "    real_url_val = \"http://www.riss.kr\" + bring_url_pre[n][0].get('href')\n",
    "    real_url.append(real_url_val)\n",
    "    driver.get(real_url[n])\n",
    "    time.sleep(2)\n",
    "    real_page_source_val = driver.page_source\n",
    "    real_page_source.append(real_page_source_val)\n",
    "    real_soup_val = BeautifulSoup(real_page_source[n], 'html.parser')\n",
    "    real_soup.append(real_soup_val)\n",
    "    \n",
    "driver = webdriver.Chrome(executable_path='/Users/jeon-eunji/Documents/GitHub/TIL/크롤링/chromedriver')\n",
    "detail_box = []\n",
    "title = []\n",
    "저자 = []\n",
    "발행기관 = []\n",
    "발행연도 = []\n",
    "핵심어 = []\n",
    "주제어 = []\n",
    "reference_data = pd.DataFrame(columns = ['title', '저자', '발행기관', '발행연도', '핵심어'])\n",
    "############ 제목 ############\n",
    "for r in range(len(real_soup)):\n",
    "    detail_title = real_soup[r].find(\"h3\", \"title\")\n",
    "#get_text()메서드는 현재 태그를 포함하여 모든 하위 태그를 제거하고 유니코드 텍스트만 들어있는 문자열을 반환한다.\n",
    "    title_txt_val1 = detail_title.get_text(\"\", strip = True)\n",
    "    title_txt_val2 = title_txt_val1.replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "    title.append(title_txt_val2)\n",
    "    title_df = pd.DataFrame(title)\n",
    "######저자[0], 발행기관[1], 발행연도 [4], 주제어\n",
    "    detail = real_soup[r].select('div.infoDetailL > ul > li')\n",
    "    \n",
    "    저자_val = detail[0].find_all(\"a\")[0].get_text(\"\", strip = True)\n",
    "    저자.append(저자_val)\n",
    "    저자_df = pd.DataFrame(저자)\n",
    "    \n",
    "    발행기관_val = detail[1].find_all(\"a\")[0].get_text(\"\", strip=True)\n",
    "    발행기관.append(발행기관_val)\n",
    "    발행기관_df = pd.DataFrame(발행기관)\n",
    "    \n",
    "    발행연도_val = detail[4].find_all(\"p\")[0].get_text(\"\", strip = True)\n",
    "    발행연도.append(발행연도_val)\n",
    "    발행연도_df = pd.DataFrame(발행연도)\n",
    "\n",
    "###핵심어\n",
    "핵심어 = pd.DataFrame(index=range(0,len(real_soup)), columns = {'s'})\n",
    "핵심어[\"s\"] = np.nan\n",
    "\n",
    "for r in range(len(real_soup)):\n",
    "    detail = real_soup[r].select('div.infoDetailL > ul > li')\n",
    "    주제어 = []\n",
    "    for i in range(len(detail[6].find_all(\"a\"))): \n",
    "        detail_1_val = detail[6].find_all(\"a\")[i].get_text(\"\", strip = True)\n",
    "        주제어.append(detail_1_val)\n",
    "        핵심어.loc[r,'s'] = 주제어\n",
    "핵심어\n",
    "\n",
    "##합치기\n",
    "reference_1 = pd.concat([title_df, 저자_df, 발행기관_df, 발행연도_df], axis=1)\n",
    "reference_1\n",
    "\n",
    "교통약자_data05 = pd.concat([reference_1, 핵심어], axis = 1)\n",
    "교통약자_data05.columns = ['title', '저자', '발행기관', '발행연도', '핵심어']\n",
    "교통약자_data05\n",
    "교통약자_data05.to_csv(\"교통약자05.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2d50c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path='/Users/jeon-eunji/Documents/GitHub/TIL/크롤링/chromedriver')\n",
    "front = []\n",
    "letsdigin = []\n",
    "bring_url_pre = []\n",
    "n_url = []\n",
    "real_url = []\n",
    "real_t = []\n",
    "realsoup = []\n",
    "real_page_source = []\n",
    "real_soup = []\n",
    "\n",
    "\n",
    "\n",
    "가져올페이지수 = 5\n",
    "for i in range(40, 45):\n",
    "    get_t_v = requests.get(page_URL[i])\n",
    "    soup = BeautifulSoup(get_t_v.content, 'html.parser')\n",
    "    front.append(soup)\n",
    "for i in range(가져올페이지수):\n",
    "    dig_in = front[i].select('div.srchResultListW > ul > li')  \n",
    "    for j in range(0,10):\n",
    "        inval = dig_in[j].find('p', {'class' :'title'})\n",
    "        letsdigin.append(inval)\n",
    "for page in range(가져올페이지수*10):\n",
    "    bring_url_pre_val = letsdigin[page].select('a')\n",
    "    bring_url_pre.append(bring_url_pre_val)\n",
    "\n",
    "for n in range(len(bring_url_pre)):\n",
    "    real_url_val = \"http://www.riss.kr\" + bring_url_pre[n][0].get('href')\n",
    "    real_url.append(real_url_val)\n",
    "    driver.get(real_url[n])\n",
    "    time.sleep(2)\n",
    "    real_page_source_val = driver.page_source\n",
    "    real_page_source.append(real_page_source_val)\n",
    "    real_soup_val = BeautifulSoup(real_page_source[n], 'html.parser')\n",
    "    real_soup.append(real_soup_val)\n",
    "    \n",
    "driver = webdriver.Chrome(executable_path='/Users/jeon-eunji/Documents/GitHub/TIL/크롤링/chromedriver')\n",
    "detail_box = []\n",
    "title = []\n",
    "저자 = []\n",
    "발행기관 = []\n",
    "발행연도 = []\n",
    "핵심어 = []\n",
    "주제어 = []\n",
    "reference_data = pd.DataFrame(columns = ['title', '저자', '발행기관', '발행연도', '핵심어'])\n",
    "############ 제목 ############\n",
    "for r in range(len(real_soup)):\n",
    "    detail_title = real_soup[r].find(\"h3\", \"title\")\n",
    "#get_text()메서드는 현재 태그를 포함하여 모든 하위 태그를 제거하고 유니코드 텍스트만 들어있는 문자열을 반환한다.\n",
    "    title_txt_val1 = detail_title.get_text(\"\", strip = True)\n",
    "    title_txt_val2 = title_txt_val1.replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "    title.append(title_txt_val2)\n",
    "    title_df = pd.DataFrame(title)\n",
    "######저자[0], 발행기관[1], 발행연도 [4], 주제어\n",
    "    detail = real_soup[r].select('div.infoDetailL > ul > li')\n",
    "    \n",
    "    저자_val = detail[0].find_all(\"a\")[0].get_text(\"\", strip = True)\n",
    "    저자.append(저자_val)\n",
    "    저자_df = pd.DataFrame(저자)\n",
    "    \n",
    "    발행기관_val = detail[1].find_all(\"a\")[0].get_text(\"\", strip=True)\n",
    "    발행기관.append(발행기관_val)\n",
    "    발행기관_df = pd.DataFrame(발행기관)\n",
    "    \n",
    "    발행연도_val = detail[4].find_all(\"p\")[0].get_text(\"\", strip = True)\n",
    "    발행연도.append(발행연도_val)\n",
    "    발행연도_df = pd.DataFrame(발행연도)\n",
    "\n",
    "###핵심어\n",
    "핵심어 = pd.DataFrame(index=range(0,len(real_soup)), columns = {'s'})\n",
    "핵심어[\"s\"] = np.nan\n",
    "\n",
    "for r in range(len(real_soup)):\n",
    "    detail = real_soup[r].select('div.infoDetailL > ul > li')\n",
    "    주제어 = []\n",
    "    for i in range(len(detail[6].find_all(\"a\"))): \n",
    "        detail_1_val = detail[6].find_all(\"a\")[i].get_text(\"\", strip = True)\n",
    "        주제어.append(detail_1_val)\n",
    "        핵심어.loc[r,'s'] = 주제어\n",
    "핵심어\n",
    "\n",
    "##합치기\n",
    "reference_1 = pd.concat([title_df, 저자_df, 발행기관_df, 발행연도_df], axis=1)\n",
    "reference_1\n",
    "\n",
    "교통약자_data06 = pd.concat([reference_1, 핵심어], axis = 1)\n",
    "교통약자_data06.columns = ['title', '저자', '발행기관', '발행연도', '핵심어']\n",
    "교통약자_data06\n",
    "교통약자_data06.to_csv(\"교통약자06.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e47e2909",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path='/Users/jeon-eunji/Documents/GitHub/TIL/크롤링/chromedriver')\n",
    "front = []\n",
    "letsdigin = []\n",
    "bring_url_pre = []\n",
    "n_url = []\n",
    "real_url = []\n",
    "real_t = []\n",
    "realsoup = []\n",
    "real_page_source = []\n",
    "real_soup = []\n",
    "\n",
    "\n",
    "\n",
    "가져올페이지수 = 5\n",
    "for i in range(45, 50):\n",
    "    get_t_v = requests.get(page_URL[i])\n",
    "    soup = BeautifulSoup(get_t_v.content, 'html.parser')\n",
    "    front.append(soup)\n",
    "for i in range(가져올페이지수):\n",
    "    dig_in = front[i].select('div.srchResultListW > ul > li')  \n",
    "    for j in range(0,10):\n",
    "        inval = dig_in[j].find('p', {'class' :'title'})\n",
    "        letsdigin.append(inval)\n",
    "for page in range(가져올페이지수*10):\n",
    "    bring_url_pre_val = letsdigin[page].select('a')\n",
    "    bring_url_pre.append(bring_url_pre_val)\n",
    "\n",
    "for n in range(len(bring_url_pre)):\n",
    "    real_url_val = \"http://www.riss.kr\" + bring_url_pre[n][0].get('href')\n",
    "    real_url.append(real_url_val)\n",
    "    driver.get(real_url[n])\n",
    "    time.sleep(2)\n",
    "    real_page_source_val = driver.page_source\n",
    "    real_page_source.append(real_page_source_val)\n",
    "    real_soup_val = BeautifulSoup(real_page_source[n], 'html.parser')\n",
    "    real_soup.append(real_soup_val)\n",
    "    \n",
    "driver = webdriver.Chrome(executable_path='/Users/jeon-eunji/Documents/GitHub/TIL/크롤링/chromedriver')\n",
    "detail_box = []\n",
    "title = []\n",
    "저자 = []\n",
    "발행기관 = []\n",
    "발행연도 = []\n",
    "핵심어 = []\n",
    "주제어 = []\n",
    "reference_data = pd.DataFrame(columns = ['title', '저자', '발행기관', '발행연도', '핵심어'])\n",
    "############ 제목 ############\n",
    "for r in range(len(real_soup)):\n",
    "    detail_title = real_soup[r].find(\"h3\", \"title\")\n",
    "#get_text()메서드는 현재 태그를 포함하여 모든 하위 태그를 제거하고 유니코드 텍스트만 들어있는 문자열을 반환한다.\n",
    "    title_txt_val1 = detail_title.get_text(\"\", strip = True)\n",
    "    title_txt_val2 = title_txt_val1.replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "    title.append(title_txt_val2)\n",
    "    title_df = pd.DataFrame(title)\n",
    "######저자[0], 발행기관[1], 발행연도 [4], 주제어\n",
    "    detail = real_soup[r].select('div.infoDetailL > ul > li')\n",
    "    \n",
    "    저자_val = detail[0].find_all(\"a\")[0].get_text(\"\", strip = True)\n",
    "    저자.append(저자_val)\n",
    "    저자_df = pd.DataFrame(저자)\n",
    "    \n",
    "    발행기관_val = detail[1].find_all(\"a\")[0].get_text(\"\", strip=True)\n",
    "    발행기관.append(발행기관_val)\n",
    "    발행기관_df = pd.DataFrame(발행기관)\n",
    "    \n",
    "    발행연도_val = detail[4].find_all(\"p\")[0].get_text(\"\", strip = True)\n",
    "    발행연도.append(발행연도_val)\n",
    "    발행연도_df = pd.DataFrame(발행연도)\n",
    "\n",
    "###핵심어\n",
    "핵심어 = pd.DataFrame(index=range(0,len(real_soup)), columns = {'s'})\n",
    "핵심어[\"s\"] = np.nan\n",
    "\n",
    "for r in range(len(real_soup)):\n",
    "    detail = real_soup[r].select('div.infoDetailL > ul > li')\n",
    "    주제어 = []\n",
    "    for i in range(len(detail[6].find_all(\"a\"))): \n",
    "        detail_1_val = detail[6].find_all(\"a\")[i].get_text(\"\", strip = True)\n",
    "        주제어.append(detail_1_val)\n",
    "        핵심어.loc[r,'s'] = 주제어\n",
    "핵심어\n",
    "\n",
    "##합치기\n",
    "reference_1 = pd.concat([title_df, 저자_df, 발행기관_df, 발행연도_df], axis=1)\n",
    "reference_1\n",
    "\n",
    "교통약자_data07 = pd.concat([reference_1, 핵심어], axis = 1)\n",
    "교통약자_data07.columns = ['title', '저자', '발행기관', '발행연도', '핵심어']\n",
    "교통약자_data07\n",
    "교통약자_data07.to_csv(\"교통약자07.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31ea634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path='/Users/jeon-eunji/Documents/GitHub/TIL/크롤링/chromedriver')\n",
    "front = []\n",
    "letsdigin = []\n",
    "bring_url_pre = []\n",
    "n_url = []\n",
    "real_url = []\n",
    "real_t = []\n",
    "realsoup = []\n",
    "real_page_source = []\n",
    "real_soup = []\n",
    "\n",
    "\n",
    "\n",
    "가져올페이지수 = 5\n",
    "for i in range(50, 55):\n",
    "    get_t_v = requests.get(page_URL[i])\n",
    "    soup = BeautifulSoup(get_t_v.content, 'html.parser')\n",
    "    front.append(soup)\n",
    "for i in range(가져올페이지수):\n",
    "    dig_in = front[i].select('div.srchResultListW > ul > li')  \n",
    "    for j in range(0,10):\n",
    "        inval = dig_in[j].find('p', {'class' :'title'})\n",
    "        letsdigin.append(inval)\n",
    "for page in range(가져올페이지수*10):\n",
    "    bring_url_pre_val = letsdigin[page].select('a')\n",
    "    bring_url_pre.append(bring_url_pre_val)\n",
    "\n",
    "for n in range(len(bring_url_pre)):\n",
    "    real_url_val = \"http://www.riss.kr\" + bring_url_pre[n][0].get('href')\n",
    "    real_url.append(real_url_val)\n",
    "    driver.get(real_url[n])\n",
    "    time.sleep(2)\n",
    "    real_page_source_val = driver.page_source\n",
    "    real_page_source.append(real_page_source_val)\n",
    "    real_soup_val = BeautifulSoup(real_page_source[n], 'html.parser')\n",
    "    real_soup.append(real_soup_val)\n",
    "    \n",
    "driver = webdriver.Chrome(executable_path='/Users/jeon-eunji/Documents/GitHub/TIL/크롤링/chromedriver')\n",
    "detail_box = []\n",
    "title = []\n",
    "저자 = []\n",
    "발행기관 = []\n",
    "발행연도 = []\n",
    "핵심어 = []\n",
    "주제어 = []\n",
    "reference_data = pd.DataFrame(columns = ['title', '저자', '발행기관', '발행연도', '핵심어'])\n",
    "############ 제목 ############\n",
    "for r in range(len(real_soup)):\n",
    "    detail_title = real_soup[r].find(\"h3\", \"title\")\n",
    "#get_text()메서드는 현재 태그를 포함하여 모든 하위 태그를 제거하고 유니코드 텍스트만 들어있는 문자열을 반환한다.\n",
    "    title_txt_val1 = detail_title.get_text(\"\", strip = True)\n",
    "    title_txt_val2 = title_txt_val1.replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "    title.append(title_txt_val2)\n",
    "    title_df = pd.DataFrame(title)\n",
    "######저자[0], 발행기관[1], 발행연도 [4], 주제어\n",
    "    detail = real_soup[r].select('div.infoDetailL > ul > li')\n",
    "    \n",
    "    저자_val = detail[0].find_all(\"a\")[0].get_text(\"\", strip = True)\n",
    "    저자.append(저자_val)\n",
    "    저자_df = pd.DataFrame(저자)\n",
    "    \n",
    "    발행기관_val = detail[1].find_all(\"a\")[0].get_text(\"\", strip=True)\n",
    "    발행기관.append(발행기관_val)\n",
    "    발행기관_df = pd.DataFrame(발행기관)\n",
    "    \n",
    "    발행연도_val = detail[4].find_all(\"p\")[0].get_text(\"\", strip = True)\n",
    "    발행연도.append(발행연도_val)\n",
    "    발행연도_df = pd.DataFrame(발행연도)\n",
    "\n",
    "###핵심어\n",
    "핵심어 = pd.DataFrame(index=range(0,len(real_soup)), columns = {'s'})\n",
    "핵심어[\"s\"] = np.nan\n",
    "\n",
    "for r in range(len(real_soup)):\n",
    "    detail = real_soup[r].select('div.infoDetailL > ul > li')\n",
    "    주제어 = []\n",
    "    for i in range(len(detail[6].find_all(\"a\"))): \n",
    "        detail_1_val = detail[6].find_all(\"a\")[i].get_text(\"\", strip = True)\n",
    "        주제어.append(detail_1_val)\n",
    "        핵심어.loc[r,'s'] = 주제어\n",
    "핵심어\n",
    "\n",
    "##합치기\n",
    "reference_1 = pd.concat([title_df, 저자_df, 발행기관_df, 발행연도_df], axis=1)\n",
    "reference_1\n",
    "\n",
    "교통약자_data08 = pd.concat([reference_1, 핵심어], axis = 1)\n",
    "교통약자_data08.columns = ['title', '저자', '발행기관', '발행연도', '핵심어']\n",
    "교통약자_data08\n",
    "교통약자_data08.to_csv(\"교통약자08.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1bbc664",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path='/Users/jeon-eunji/Documents/GitHub/TIL/크롤링/chromedriver')\n",
    "front = []\n",
    "letsdigin = []\n",
    "bring_url_pre = []\n",
    "n_url = []\n",
    "real_url = []\n",
    "real_t = []\n",
    "realsoup = []\n",
    "real_page_source = []\n",
    "real_soup = []\n",
    "\n",
    "\n",
    "\n",
    "가져올페이지수 = 5\n",
    "for i in range(55, 60):\n",
    "    get_t_v = requests.get(page_URL[i])\n",
    "    soup = BeautifulSoup(get_t_v.content, 'html.parser')\n",
    "    front.append(soup)\n",
    "for i in range(가져올페이지수):\n",
    "    dig_in = front[i].select('div.srchResultListW > ul > li')  \n",
    "    for j in range(0,10):\n",
    "        inval = dig_in[j].find('p', {'class' :'title'})\n",
    "        letsdigin.append(inval)\n",
    "for page in range(가져올페이지수*10):\n",
    "    bring_url_pre_val = letsdigin[page].select('a')\n",
    "    bring_url_pre.append(bring_url_pre_val)\n",
    "\n",
    "for n in range(len(bring_url_pre)):\n",
    "    real_url_val = \"http://www.riss.kr\" + bring_url_pre[n][0].get('href')\n",
    "    real_url.append(real_url_val)\n",
    "    driver.get(real_url[n])\n",
    "    time.sleep(2)\n",
    "    real_page_source_val = driver.page_source\n",
    "    real_page_source.append(real_page_source_val)\n",
    "    real_soup_val = BeautifulSoup(real_page_source[n], 'html.parser')\n",
    "    real_soup.append(real_soup_val)\n",
    "    \n",
    "driver = webdriver.Chrome(executable_path='/Users/jeon-eunji/Documents/GitHub/TIL/크롤링/chromedriver')\n",
    "detail_box = []\n",
    "title = []\n",
    "저자 = []\n",
    "발행기관 = []\n",
    "발행연도 = []\n",
    "핵심어 = []\n",
    "주제어 = []\n",
    "reference_data = pd.DataFrame(columns = ['title', '저자', '발행기관', '발행연도', '핵심어'])\n",
    "############ 제목 ############\n",
    "for r in range(len(real_soup)):\n",
    "    detail_title = real_soup[r].find(\"h3\", \"title\")\n",
    "#get_text()메서드는 현재 태그를 포함하여 모든 하위 태그를 제거하고 유니코드 텍스트만 들어있는 문자열을 반환한다.\n",
    "    title_txt_val1 = detail_title.get_text(\"\", strip = True)\n",
    "    title_txt_val2 = title_txt_val1.replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "    title.append(title_txt_val2)\n",
    "    title_df = pd.DataFrame(title)\n",
    "######저자[0], 발행기관[1], 발행연도 [4], 주제어\n",
    "    detail = real_soup[r].select('div.infoDetailL > ul > li')\n",
    "    \n",
    "    저자_val = detail[0].find_all(\"a\")[0].get_text(\"\", strip = True)\n",
    "    저자.append(저자_val)\n",
    "    저자_df = pd.DataFrame(저자)\n",
    "    \n",
    "    발행기관_val = detail[1].find_all(\"a\")[0].get_text(\"\", strip=True)\n",
    "    발행기관.append(발행기관_val)\n",
    "    발행기관_df = pd.DataFrame(발행기관)\n",
    "    \n",
    "    발행연도_val = detail[4].find_all(\"p\")[0].get_text(\"\", strip = True)\n",
    "    발행연도.append(발행연도_val)\n",
    "    발행연도_df = pd.DataFrame(발행연도)\n",
    "\n",
    "###핵심어\n",
    "핵심어 = pd.DataFrame(index=range(0,len(real_soup)), columns = {'s'})\n",
    "핵심어[\"s\"] = np.nan\n",
    "\n",
    "for r in range(len(real_soup)):\n",
    "    detail = real_soup[r].select('div.infoDetailL > ul > li')\n",
    "    주제어 = []\n",
    "    for i in range(len(detail[6].find_all(\"a\"))): \n",
    "        detail_1_val = detail[6].find_all(\"a\")[i].get_text(\"\", strip = True)\n",
    "        주제어.append(detail_1_val)\n",
    "        핵심어.loc[r,'s'] = 주제어\n",
    "핵심어\n",
    "\n",
    "##합치기\n",
    "reference_1 = pd.concat([title_df, 저자_df, 발행기관_df, 발행연도_df], axis=1)\n",
    "reference_1\n",
    "\n",
    "교통약자_data09 = pd.concat([reference_1, 핵심어], axis = 1)\n",
    "교통약자_data09.columns = ['title', '저자', '발행기관', '발행연도', '핵심어']\n",
    "교통약자_data09\n",
    "교통약자_data09.to_csv(\"교통약자09.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26df928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path='/Users/jeon-eunji/Documents/GitHub/TIL/크롤링/chromedriver')\n",
    "front = []\n",
    "letsdigin = []\n",
    "bring_url_pre = []\n",
    "n_url = []\n",
    "real_url = []\n",
    "real_t = []\n",
    "realsoup = []\n",
    "real_page_source = []\n",
    "real_soup = []\n",
    "\n",
    "\n",
    "\n",
    "가져올페이지수 = 5\n",
    "for i in range(60, 65):\n",
    "    get_t_v = requests.get(page_URL[i])\n",
    "    soup = BeautifulSoup(get_t_v.content, 'html.parser')\n",
    "    front.append(soup)\n",
    "for i in range(가져올페이지수):\n",
    "    dig_in = front[i].select('div.srchResultListW > ul > li')  \n",
    "    for j in range(0,10):\n",
    "        inval = dig_in[j].find('p', {'class' :'title'})\n",
    "        letsdigin.append(inval)\n",
    "for page in range(가져올페이지수*10):\n",
    "    bring_url_pre_val = letsdigin[page].select('a')\n",
    "    bring_url_pre.append(bring_url_pre_val)\n",
    "\n",
    "for n in range(len(bring_url_pre)):\n",
    "    real_url_val = \"http://www.riss.kr\" + bring_url_pre[n][0].get('href')\n",
    "    real_url.append(real_url_val)\n",
    "    driver.get(real_url[n])\n",
    "    time.sleep(2)\n",
    "    real_page_source_val = driver.page_source\n",
    "    real_page_source.append(real_page_source_val)\n",
    "    real_soup_val = BeautifulSoup(real_page_source[n], 'html.parser')\n",
    "    real_soup.append(real_soup_val)\n",
    "    \n",
    "driver = webdriver.Chrome(executable_path='/Users/jeon-eunji/Documents/GitHub/TIL/크롤링/chromedriver')\n",
    "detail_box = []\n",
    "title = []\n",
    "저자 = []\n",
    "발행기관 = []\n",
    "발행연도 = []\n",
    "핵심어 = []\n",
    "주제어 = []\n",
    "reference_data = pd.DataFrame(columns = ['title', '저자', '발행기관', '발행연도', '핵심어'])\n",
    "############ 제목 ############\n",
    "for r in range(len(real_soup)):\n",
    "    detail_title = real_soup[r].find(\"h3\", \"title\")\n",
    "#get_text()메서드는 현재 태그를 포함하여 모든 하위 태그를 제거하고 유니코드 텍스트만 들어있는 문자열을 반환한다.\n",
    "    title_txt_val1 = detail_title.get_text(\"\", strip = True)\n",
    "    title_txt_val2 = title_txt_val1.replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "    title.append(title_txt_val2)\n",
    "    title_df = pd.DataFrame(title)\n",
    "######저자[0], 발행기관[1], 발행연도 [4], 주제어\n",
    "    detail = real_soup[r].select('div.infoDetailL > ul > li')\n",
    "    \n",
    "    저자_val = detail[0].find_all(\"a\")[0].get_text(\"\", strip = True)\n",
    "    저자.append(저자_val)\n",
    "    저자_df = pd.DataFrame(저자)\n",
    "    \n",
    "    발행기관_val = detail[1].find_all(\"a\")[0].get_text(\"\", strip=True)\n",
    "    발행기관.append(발행기관_val)\n",
    "    발행기관_df = pd.DataFrame(발행기관)\n",
    "    \n",
    "    발행연도_val = detail[4].find_all(\"p\")[0].get_text(\"\", strip = True)\n",
    "    발행연도.append(발행연도_val)\n",
    "    발행연도_df = pd.DataFrame(발행연도)\n",
    "\n",
    "###핵심어\n",
    "핵심어 = pd.DataFrame(index=range(0,len(real_soup)), columns = {'s'})\n",
    "핵심어[\"s\"] = np.nan\n",
    "\n",
    "for r in range(len(real_soup)):\n",
    "    detail = real_soup[r].select('div.infoDetailL > ul > li')\n",
    "    주제어 = []\n",
    "    for i in range(len(detail[6].find_all(\"a\"))): \n",
    "        detail_1_val = detail[6].find_all(\"a\")[i].get_text(\"\", strip = True)\n",
    "        주제어.append(detail_1_val)\n",
    "        핵심어.loc[r,'s'] = 주제어\n",
    "핵심어\n",
    "\n",
    "##합치기\n",
    "reference_1 = pd.concat([title_df, 저자_df, 발행기관_df, 발행연도_df], axis=1)\n",
    "reference_1\n",
    "\n",
    "교통약자_data10 = pd.concat([reference_1, 핵심어], axis = 1)\n",
    "교통약자_data10.columns = ['title', '저자', '발행기관', '발행연도', '핵심어']\n",
    "교통약자_data10\n",
    "교통약자_data10.to_csv(\"교통약자10.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bfbafb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df3cbe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
